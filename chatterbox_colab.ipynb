{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Chatterbox TTS - Colab Notebook\n",
    "This notebook demonstrates how to use Chatterbox, a state-of-the-art open-source TTS model. Follow the steps below to get started."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Install Dependencies\n",
    "First, let's install the required packages."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["!pip install chatterbox-tts gradio"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Import Libraries and Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import torchaudio as ta\n",
    "import torch\n",
    "from chatterbox.tts import ChatterboxTTS\n",
    "\n",
    "# Automatically detect the best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Load the Model\n",
    "Now we'll load the pre-trained Chatterbox TTS model."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["model = ChatterboxTTS.from_pretrained(device=device)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Generate Speech from Text\n",
    "Let's generate some speech using the default voice."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["text = \"Hello! This is a test of the Chatterbox TTS system. It can generate natural-sounding speech from text.\"\n",
    "wav = model.generate(text)\n",
    "\n",
    "# Save the generated audio\n",
    "output_path = \"test_output.wav\"\n",
    "ta.save(output_path, wav, model.sr)\n",
    "\n",
    "# Display audio player in the notebook\n",
    "from IPython.display import Audio\n",
    "Audio(output_path)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Voice Cloning (Optional)\n",
    "You can also clone a voice by providing an audio prompt. Upload your audio file and specify its path below."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Upload your audio file and set its path here\n",
    "AUDIO_PROMPT_PATH = \"path_to_your_audio.wav\"  # Replace with your audio file path\n",
    "\n",
    "# Generate speech with the voice from the audio prompt\n",
    "text = \"This is the same text but spoken in a different voice.\"\n",
    "wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)\n",
    "\n",
    "# Save and play the generated audio\n",
    "output_path_cloned = \"test_output_cloned.wav\"\n",
    "ta.save(output_path_cloned, wav, model.sr)\n",
    "Audio(output_path_cloned)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Gradio UI with Live Server"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import gradio as gr\n", "\n", "def generate_with_gradio(text, audio_prompt, exaggeration, temperature, cfgw, min_p, top_p, repetition_penalty, max_new_tokens):\n", "    try:\n", "        # The model is already loaded in the notebook's global state\n", "        audio_prompt_path = audio_prompt if audio_prompt else None\n", "        wav = model.generate(\n", "            text,\n", "            audio_prompt_path=audio_prompt_path,\n", "            exaggeration=exaggeration,\n", "            temperature=temperature,\n", "            cfg_weight=cfgw,\n", "            min_p=min_p,\n", "            top_p=top_p,\n", "            repetition_penalty=repetition_penalty,\n", "            max_new_tokens=int(max_new_tokens),\n", "        )\n", "        return (model.sr, wav.squeeze(0).numpy()), None\n", "    except Exception as e:\n", "        return None, str(e)\n", "\n", "with gr.Blocks() as demo:\n", "    with gr.Row():\n", "        with gr.Column():\n", "            text = gr.Textbox(\n", "                value=\"Now let's make my mum's favourite. So three mars bars into the pan. Then we add the tuna and just stir for a bit, just let the chocolate and fish infuse. A sprinkle of olive oil and some tomato ketchup. Now smell that. Oh boy this is going to be incredible.\",\n", "                label=\"Text to synthesize\",\n", "                max_lines=5\n", "            )\n", "            ref_wav = gr.Audio(sources=[\"upload\", \"microphone\"], type=\"filepath\", label=\"Reference Audio File\", value=None)\n", "            exaggeration = gr.Slider(0.25, 2, step=.05, label=\"Exaggeration (Neutral = 0.5, extreme values can be unstable)\", value=.5)\n", "            cfg_weight = gr.Slider(0.0, 1, step=.05, label=\"CFG/Pace\", value=0.5)\n", "\n", "            with gr.Accordion(\"More options\", open=False):\n", "                temp = gr.Slider(0.05, 5, step=.05, label=\"temperature\", value=.8)\n", "                min_p = gr.Slider(0.00, 1.00, step=0.01, label=\"min_p || Newer Sampler. Recommend 0.02 > 0.1. Handles Higher Temperatures better. 0.00 Disables\", value=0.05)\n", "                top_p = gr.Slider(0.00, 1.00, step=0.01, label=\"top_p || Original Sampler. 1.0 Disables(recommended). Original 0.8\", value=1.00)\n", "                repetition_penalty = gr.Slider(1.00, 2.00, step=0.1, label=\"repetition_penalty\", value=1.2)\n", "                max_new_tokens = gr.Slider(100, 2000, step=50, label=\"Max New Tokens\", value=1000)\n", "\n", "            run_btn = gr.Button(\"Generate\", variant=\"primary\")\n", "\n", "        with gr.Column():\n", "            audio_output = gr.Audio(label=\"Output Audio\")\n", "            error_output = gr.Textbox(label=\"Error\", visible=False)\n", "\n", "    def show_error(error_message):\n", "        if error_message:\n", "            return gr.update(visible=True, value=error_message)\n", "        return gr.update(visible=False)\n", "\n", "    run_btn.click(\n", "        fn=generate_with_gradio,\n", "        inputs=[\n", "            text,\n", "            ref_wav,\n", "            exaggeration,\n", "            temp,\n", "            cfg_weight,\n", "            min_p,\n", "            top_p,\n", "            repetition_penalty,\n", "            max_new_tokens,\n", "        ],\n", "        outputs=[audio_output, error_output],\n", "    ).then(show_error, inputs=error_output, outputs=error_output)\n", "\n", "demo.launch(share=True)"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}